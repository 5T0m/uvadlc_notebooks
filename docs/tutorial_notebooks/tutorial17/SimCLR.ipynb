{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contrastive Learning: SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "import json\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## tqdm for loading bars\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "## Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import STL10\n",
    "from torchvision import transforms\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install pytorch-lightning==1.3.4\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "# Import tensorboard\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial17\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.error import HTTPError\n",
    "# Github URL where saved models are stored for this tutorial\n",
    "base_url = \"https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial17/\"\n",
    "# Files to download\n",
    "pretrained_files = []\n",
    "# Create checkpoint path if it doesn't exist yet\n",
    "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
    "\n",
    "# For each file, check whether it already exists. If not, try downloading it.\n",
    "for file_name in pretrained_files:\n",
    "    file_path = os.path.join(CHECKPOINT_PATH, file_name)\n",
    "    if \"/\" in file_name:\n",
    "        os.makedirs(file_path.rsplit(\"/\",1)[0], exist_ok=True)\n",
    "    if not os.path.isfile(file_path):\n",
    "        file_url = base_url + file_name\n",
    "        print(\"Downloading %s...\" % file_url)\n",
    "        try:\n",
    "            urllib.request.urlretrieve(file_url, file_path)\n",
    "        except HTTPError as e:\n",
    "            print(\"Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\\n\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveTransformations(object):\n",
    "    \n",
    "    def __init__(self, base_transforms, n_views=2):\n",
    "        self.base_transforms = base_transforms\n",
    "        self.n_views = n_views\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        return [self.base_transforms(x) for i in range(self.n_views)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrast_transforms = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                          transforms.RandomResizedCrop(size=96),\n",
    "                                          transforms.RandomApply([\n",
    "                                              transforms.ColorJitter(brightness=0.5, \n",
    "                                                                     contrast=0.5, \n",
    "                                                                     saturation=0.5, \n",
    "                                                                     hue=0.1)\n",
    "                                          ], p=0.8),\n",
    "                                          transforms.RandomGrayscale(p=0.2),\n",
    "                                          transforms.GaussianBlur(kernel_size=9),\n",
    "                                          transforms.ToTensor(),\n",
    "                                          transforms.Normalize((0.5,), (0.5,))\n",
    "                                         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "unlabeled_data = STL10(root=DATASET_PATH, split='unlabeled', download=True, \n",
    "                       transform=ContrastiveTransformations(contrast_transforms, n_views=2))\n",
    "train_data_contrast = STL10(root=DATASET_PATH, split='train', download=True, \n",
    "                            transform=ContrastiveTransformations(contrast_transforms, n_views=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code box\n",
    "#Visualize some examples\n",
    "NUM_IMAGES = 4\n",
    "imgs = torch.stack([img for idx in range(NUM_IMAGES) for img in unlabeled_data[idx][0]], dim=0)\n",
    "img_grid = torchvision.utils.make_grid(imgs, nrow=4, normalize=True, pad_value=0.9)\n",
    "img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title(\"Image examples of the STL10 dataset\")\n",
    "plt.imshow(img_grid)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_convnet():\n",
    "    convnet = torchvision.models.resnet18(pretrained=False, num_classes=output_size)\n",
    "    return convnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "        self.convnet = torchvision.models.resnet18(pretrained=False, num_classes=hidden_dim)\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            self.convnet.fc,\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), \n",
    "                                lr=self.hparams.lr, \n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                      milestones=[140,180], \n",
    "                                                      gamma=0.1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "        \n",
    "    def info_nce_loss(self, batch, mode='train'):\n",
    "        imgs, _ = batch\n",
    "        imgs = torch.cat(imgs, dim=0)\n",
    "        num_imgs = imgs.shape[0]\n",
    "        \n",
    "        feats = self.convnet(imgs)\n",
    "        \n",
    "        cos_sim = F.cosine_similarity(feats[:,None,:], feats[None,:,:], dim=-1)\n",
    "        pos_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        pos_mask = pos_mask.roll(shifts=cos_sim.shape[0]//2, dims=0)\n",
    "        neg_mask = ~pos_mask\n",
    "        neg_mask.fill_diagonal_(False)\n",
    "\n",
    "        pos_sim = cos_sim[pos_mask].view(num_imgs, 1)\n",
    "        neg_sim = cos_sim[neg_mask].view(num_imgs, -1)\n",
    "        comb_sim = torch.cat([pos_sim, neg_sim], dim=-1)\n",
    "        nll = -F.log_softmax(comb_sim / self.hparams.temperature, dim=-1)[:,0]\n",
    "        nll = nll.mean()\n",
    "        \n",
    "        self.log(mode+'_loss', nll)\n",
    "\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        self.log(mode+'_acc_top1', (sim_argsort == 0).float().mean())\n",
    "        self.log(mode+'_acc_top5', (sim_argsort < 5).float().mean())\n",
    "        self.log(mode+'_acc_mean_pos', 1+sim_argsort.float().mean())\n",
    "        \n",
    "        return nll\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='train')\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simclr(batch_size, max_epochs=200, **kwargs):\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"SimCLR\"),\n",
    "                         gpus=1 if str(device)==\"cuda:0\" else 0,\n",
    "                         max_epochs=max_epochs,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc_top5\"),\n",
    "                                    LearningRateMonitor(\"epoch\")],\n",
    "                         progress_bar_refresh_rate=0)\n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"SimCLR.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model at %s, loading...\" % pretrained_filename)\n",
    "        model = SimCLR.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        train_loader = data.DataLoader(unlabeled_data, batch_size=batch_size, shuffle=True, \n",
    "                                       drop_last=True, pin_memory=True, num_workers=16)\n",
    "        val_loader = data.DataLoader(train_data_contrast, batch_size=batch_size, shuffle=False, \n",
    "                                     drop_last=False, pin_memory=True, num_workers=8)\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = SimCLR(**kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "/home/phillip/anaconda3/envs/dl2020/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:69: UserWarning: Could not log computational graph since the `model.example_input_array` attribute is not set or `input_array` was not given\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  | Name    | Type   | Params\n",
      "-----------------------------------\n",
      "0 | convnet | ResNet | 11.3 M\n",
      "-----------------------------------\n",
      "11.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.3 M    Total params\n",
      "45.035    Total estimated model params size (MB)\n",
      "/home/phillip/anaconda3/envs/dl2020/lib/python3.7/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448265233/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
      "Global seed set to 42\n"
     ]
    }
   ],
   "source": [
    "simclr_model = train_simclr(batch_size=256, \n",
    "                            hidden_dim=128, \n",
    "                            lr=5e-4, \n",
    "                            temperature=0.07, \n",
    "                            weight_decay=1e-4, \n",
    "                            max_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, feature_dim, num_classes, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.model = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), \n",
    "                                lr=self.hparams.lr, \n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer, \n",
    "                                                      milestones=[60, 80], \n",
    "                                                      gamma=0.1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "        \n",
    "    def _calculate_loss(self, batch, mode='train'):\n",
    "        feats, labels = batch\n",
    "        preds = self.model(feats)\n",
    "        loss = F.cross_entropy(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log(mode + '_loss', loss)\n",
    "        self.log(mode + '_acc', acc)\n",
    "        return loss        \n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode='train')\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='val')\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "img_transforms = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_img_data = STL10(root=DATASET_PATH, split='train', download=True, \n",
    "                   transform=img_transforms)\n",
    "val_img_data = STL10(root=DATASET_PATH, split='test', download=True, \n",
    "                 transform=img_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataset):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    data_loader = data.DataLoader(dataset, batch_size=64, num_workers=8, shuffle=False, drop_last=False)\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(data_loader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "    \n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    return data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f4b513d4e1d4068bccf251d581b446d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=79.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f474f69264d645e68353e34abcc9cae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=125.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_feats_data = prepare_data_features(simclr_model, train_img_data)\n",
    "val_feats_data = prepare_data_features(simclr_model, val_img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(batch_size, max_epochs=100, **kwargs):\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"LogisticRegression\"),\n",
    "                         gpus=1 if str(device)==\"cuda:0\" else 0,\n",
    "                         max_epochs=max_epochs,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "                                    LearningRateMonitor(\"epoch\")],\n",
    "                         progress_bar_refresh_rate=0,\n",
    "                         check_val_every_n_epoch=10)\n",
    "    trainer.logger._log_graph = True         # If True, we plot the computation graph in tensorboard\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "    \n",
    "    # Data loaders\n",
    "    train_loader = data.DataLoader(train_feats_data, batch_size=batch_size, shuffle=True, \n",
    "                                   drop_last=True, pin_memory=True, num_workers=4)\n",
    "    val_loader = data.DataLoader(val_feats_data, batch_size=batch_size, shuffle=False, \n",
    "                                 drop_last=False, pin_memory=True, num_workers=4)\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"LogisticRegression.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model at %s, loading...\" % pretrained_filename)\n",
    "        model = LogisticRegression.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = LogisticRegression(**kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = LogisticRegression.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    # Test best model on validation set\n",
    "    val_result = trainer.test(model, test_dataloaders=val_loader, verbose=False)\n",
    "    result = {\"val\": val_result[0][\"test_acc\"]}\n",
    "        \n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | Linear | 5.1 K \n",
      "---------------------------------\n",
      "5.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.1 K     Total params\n",
      "0.021     Total estimated model params size (MB)\n",
      "Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    }
   ],
   "source": [
    "logreg_model, logreg_result = train_logreg(batch_size=64,\n",
    "                                           feature_dim=train_feats_data.tensors[0].shape[1],\n",
    "                                           num_classes=10,\n",
    "                                           lr=3e-4,\n",
    "                                           weight_decay=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val': 0.5325000286102295}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
