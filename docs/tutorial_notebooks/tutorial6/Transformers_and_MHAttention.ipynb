{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Transformers and Multi-head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import numpy as np \n",
    "import random\n",
    "import math\n",
    "from functools import partial\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "plt.set_cmap('cividis')\n",
    "%matplotlib inline \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgb\n",
    "import matplotlib\n",
    "matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "# PyTorch Lightning\n",
    "try:\n",
    "    import pytorch_lightning as pl\n",
    "except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary\n",
    "    !pip install pytorch-lightning==1.0.3\n",
    "    import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial9\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaled Dot Product Attention:\n",
    "\n",
    "$$\\text{Attention}(Q,K,V)=\\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n",
    "    attn_logits = attn_logits / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        attn_logits = attn_logits.masked_fill(mask == 0, -9e15)\n",
    "    attention = F.softmax(attn_logits, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " tensor([[[ 0.3367,  0.1288],\n",
      "         [ 0.2345,  0.2303],\n",
      "         [-1.1229, -0.1863]]])\n",
      "K\n",
      " tensor([[[ 2.2082, -0.6380],\n",
      "         [ 0.4617,  0.2674],\n",
      "         [ 0.5349,  0.8094]]])\n",
      "V\n",
      " tensor([[[ 1.1103, -1.6898],\n",
      "         [-0.9890,  0.9580],\n",
      "         [ 1.3221,  0.8172]]])\n",
      "Values\n",
      " tensor([[[ 0.5698, -0.1520],\n",
      "         [ 0.5379, -0.0265],\n",
      "         [ 0.2246,  0.5556]]])\n",
      "Attention\n",
      " tensor([[[0.4028, 0.2886, 0.3086],\n",
      "         [0.3538, 0.3069, 0.3393],\n",
      "         [0.1303, 0.4630, 0.4067]]])\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, d_k = 1, 3, 2\n",
    "q = torch.randn(batch_size, seq_len, d_k)\n",
    "k = torch.randn(batch_size, seq_len, d_k)\n",
    "v = torch.randn(batch_size, seq_len, d_k)\n",
    "values, attention = scaled_dot_product(q, k, v)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"Values\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5698)\n",
      "tensor([0.4028, 0.2886, 0.3086])\n",
      "tensor([ 1.1103, -0.9890,  1.3221])\n"
     ]
    }
   ],
   "source": [
    "print((attention[0,0] * v[0,:,0]).sum())\n",
    "print(attention[0,0])\n",
    "print(v[0,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-head attention:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "    \\text{Multihead}(Q,K,V) & = \\text{Concat}(\\text{head}_1,...,\\text{head}_h)W^{O}\\\\\n",
    "    \\text{where} \\text{head}_i & = \\text{Attention}(QW_i^Q,KW_i^K, VW_i^V)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiheadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embed_dim, num_heads):\n",
    "        super().__init__()\n",
    "        assert embed_dim % num_heads == 0, \"Embedding dimension must be 0 modulo number of heads.\"\n",
    "        \n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "        \n",
    "        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim)\n",
    "        self.o_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        \n",
    "        self._reset_parameters()\n",
    "        \n",
    "        \n",
    "    def _reset_parameters(self):\n",
    "        pass\n",
    "        # nn.init.xavier_uniform_(self.qkv_proj.weight)\n",
    "        # nn.init.xavier_uniform_(self.o_proj.weight)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask=None, return_attention=False):\n",
    "        batch_size, seq_length, embed_dim = x.size()\n",
    "        qkv = self.qkv_proj(x)\n",
    "        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n",
    "        qkv = qkv.permute(0, 2, 1, 3) # [Batch, Head, SeqLen, Dims]\n",
    "        \n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        values, attention = scaled_dot_product(q, k, v, mask=mask)\n",
    "        values = values.permute(0, 2, 1, 3) # [Batch, SeqLen, Head, Dims]\n",
    "        values = values.reshape(batch_size, seq_length, embed_dim)\n",
    "        \n",
    "        o = self.o_proj(values)\n",
    "        \n",
    "        if return_attention:\n",
    "            return o, attention\n",
    "        else:\n",
    "            return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder-block: combining multi-head attention with linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn = MultiheadAttention(input_dim, input_dim, num_heads)\n",
    "        \n",
    "        self.linear_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, dim_feedforward),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(dim_feedforward, input_dim)\n",
    "        )\n",
    "        \n",
    "        self.norm1 = nn.LayerNorm(input_dim)\n",
    "        self.norm2 = nn.LayerNorm(input_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out = self.self_attn(x, mask=mask)\n",
    "        x = x + self.dropout(attn_out)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        linear_out = self.linear_net(x)\n",
    "        x = x + self.dropout(linear_out)\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_layers, **block_args):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])\n",
    "        \n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        for l in self.layers:\n",
    "            x = l(x, mask=mask)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def get_attention_maps(self, x, mask=None):\n",
    "        attention_maps = []\n",
    "        for l in self.layers:\n",
    "            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)\n",
    "            attention_maps.append(attn_map)\n",
    "            x = l(x)\n",
    "        return attention_maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following block is copied from [PyTorch tutorial](https://pytorch.org/tutorials/beginner/transformer_tutorial.html#define-the-model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.0, max_len=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerPredictor(pl.LightningModule):\n",
    "    \n",
    "    \n",
    "    def __init__(self, input_dim, model_dim, num_classes, num_heads, num_layers, lr=1e-3, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self._create_model()\n",
    "        \n",
    "    \n",
    "    def _create_model(self):\n",
    "        self.input_net = nn.Linear(self.hparams.input_dim, self.hparams.model_dim)\n",
    "        self.positional_encoding = PositionalEncoding(d_model=self.hparams.model_dim,\n",
    "                                                      dropout=self.hparams.dropout)\n",
    "        self.transformer = TransformerEncoder(num_layers=self.hparams.num_layers,\n",
    "                                              input_dim=self.hparams.model_dim,\n",
    "                                              dim_feedforward=2*self.hparams.model_dim,\n",
    "                                              num_heads=self.hparams.num_heads)\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.Linear(self.hparams.model_dim, self.hparams.model_dim),\n",
    "            nn.LayerNorm(self.hparams.model_dim),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(self.hparams.model_dim, self.hparams.num_classes)\n",
    "        ) \n",
    "        \n",
    "    \n",
    "    def forward(self, x, mask=None, add_positional_encoding=True):\n",
    "        # if seq_lens is not None:\n",
    "        #     mask = x.new_zeros(x.size(0), 1, x.size(1), x.size(1))\n",
    "        #     for i in range(x.size(0)):\n",
    "        #         mask[i,0,:seq_lens[i],:seq_lens[i]] = 1.0\n",
    "        # else:\n",
    "        #     mask = None\n",
    "            \n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        x = self.transformer(x, mask=mask)\n",
    "        x = self.output_net(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def get_attention_maps(self, x, mask=None, add_positional_encoding=True):\n",
    "        x = self.input_net(x)\n",
    "        if add_positional_encoding:\n",
    "            x = self.positional_encoding(x)\n",
    "        attention_maps = self.transformer.get_attention_maps(x, mask=mask)\n",
    "        return attention_maps\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.Adam(self.parameters(), lr=self.hparams.lr)\n",
    "        return optimizer\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        raise NotImplementedError    \n",
    "    \n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        raise NotImplementedError   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "* Toy task: reverse input (to visualize attention)\n",
    "* Set task: Find outlier in set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReverseDataset(data.Dataset):\n",
    "    \n",
    "    \n",
    "    def __init__(self, num_categories, seq_len, size):\n",
    "        super().__init__()\n",
    "        self.num_categories = num_categories\n",
    "        self.seq_len = seq_len\n",
    "        self.size = size\n",
    "        \n",
    "        self.data = torch.randint(self.num_categories, size=(self.size, self.seq_len))\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        inp_data = self.data[idx]\n",
    "        # labels = torch.fmod(inp_data + torch.flip(inp_data, dims=(0,)), self.num_categories)\n",
    "        labels = torch.flip(inp_data, dims=(0,))\n",
    "        # labels = torch.fmod(inp_data + 1, self.num_categories)\n",
    "        return inp_data, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = partial(ReverseDataset, 10, 16)\n",
    "train_loader = data.DataLoader(dataset(50000), batch_size=128, shuffle=True, drop_last=True, pin_memory=True)\n",
    "val_loader   = data.DataLoader(dataset(1000), batch_size=128)\n",
    "test_loader  = data.DataLoader(dataset(10000), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 0, 0, 2, 2, 6, 1, 7]), tensor([7, 1, 6, 2, 2, 0, 0, 3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversePredictor(TransformerPredictor):\n",
    "    \n",
    "    def _calculate_loss(self, batch, mode=\"train\"):\n",
    "        inp_data, labels = batch\n",
    "        inp_data = F.one_hot(inp_data, num_classes=self.hparams.num_classes).float()\n",
    "        preds = self.forward(inp_data, add_positional_encoding=True)\n",
    "        loss = F.cross_entropy(preds.view(-1,preds.size(-1)), labels.view(-1))\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "        self.log(\"%s_loss\" % mode, loss)\n",
    "        self.log(\"%s_acc\" % mode, acc)\n",
    "        return loss, acc\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss, _ = self._calculate_loss(batch, mode=\"train\")\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"val\")\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        _ = self._calculate_loss(batch, mode=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_reverse(**kwargs):\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    root_dir = os.path.join(CHECKPOINT_PATH, \"ReverseTask\")\n",
    "    os.makedirs(root_dir, exist_ok=True)\n",
    "    trainer = pl.Trainer(default_root_dir=root_dir, \n",
    "                         checkpoint_callback=ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "                         gpus=1, \n",
    "                         max_epochs=5)\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "    \n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, \"ReverseTask.ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = ReversePredictor.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        model = ReversePredictor(**kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, test_dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "I1102 20:35:25.850780 140527318042432 distributed.py:49] GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "I1102 20:35:25.852739 140527318042432 distributed.py:49] TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I1102 20:35:25.854121 140527318042432 accelerator_connector.py:385] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | input_net           | Linear             | 144   \n",
      "1 | positional_encoding | PositionalEncoding | 0     \n",
      "2 | transformer         | TransformerEncoder | 2 K   \n",
      "3 | output_net          | Sequential         | 440   \n",
      "I1102 20:35:25.885309 140527318042432 lightning.py:1290] \n",
      "  | Name                | Type               | Params\n",
      "-----------------------------------------------------------\n",
      "0 | input_net           | Linear             | 144   \n",
      "1 | positional_encoding | PositionalEncoding | 0     \n",
      "2 | transformer         | TransformerEncoder | 2 K   \n",
      "3 | output_net          | Sequential         | 440   \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a670438bcdb43608c79f70d8a1823c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52b3db31dfda42098def660bf61db866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d92a7fb03242f8b059cab2250844d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Testing', layout=Layout(flex='2'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'test': 1.0, 'val': 1.0}\n"
     ]
    }
   ],
   "source": [
    "reverse_model, reverse_result = train_reverse(input_dim=train_loader.dataset.num_categories,\n",
    "                                              model_dim=16,\n",
    "                                              num_heads=1,\n",
    "                                              num_classes=train_loader.dataset.num_categories,\n",
    "                                              num_layers=1,\n",
    "                                              dropout=0.0,\n",
    "                                              lr=5e-4)\n",
    "print(reverse_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input, labels = next(iter(val_loader))\n",
    "inp_data = F.one_hot(data_input, num_classes=reverse_model.hparams.num_classes).float()\n",
    "inp_data = inp_data.to(device)\n",
    "attention_maps = reverse_model.get_attention_maps(inp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 1, 8, 8])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_maps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_maps(input_data, attn_maps, idx=0):\n",
    "    input_data = input_data[idx].detach().cpu().numpy()\n",
    "    attn_maps = [m[idx].detach().cpu().numpy() for m in attn_maps]\n",
    "    \n",
    "    num_heads = attn_maps[0].shape[0]\n",
    "    num_layers = len(attn_maps)\n",
    "    seq_len = input_data.shape[0]\n",
    "    fig, ax = plt.subplots(num_layers, num_heads, figsize=(num_heads*4, num_layers*4))\n",
    "    if num_layers == 1:\n",
    "        ax = [ax]\n",
    "    if num_heads == 1:\n",
    "        ax = [[a] for a in ax]\n",
    "    for row in range(num_layers):\n",
    "        for column in range(num_heads):\n",
    "            ax[row][column].imshow(attn_maps[row][column], origin='lower', vmin=0, vmax=1)\n",
    "            ax[row][column].set_xticks(list(range(seq_len)))\n",
    "            ax[row][column].set_xticklabels(input_data.tolist())\n",
    "            ax[row][column].set_yticks(list(range(seq_len)))\n",
    "            ax[row][column].set_yticklabels(input_data.tolist())\n",
    "    fig.subplots_adjust(hspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/pdf": "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\n",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Created with matplotlib (https://matplotlib.org/) -->\n",
       "<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 245.2025 248.518125\" width=\"245.2025pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2020-11-02T20:35:50.895630</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 248.518125 \n",
       "L 245.2025 248.518125 \n",
       "L 245.2025 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill:none;\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 20.5625 224.64 \n",
       "L 238.0025 224.64 \n",
       "L 238.0025 7.2 \n",
       "L 20.5625 7.2 \n",
       "z\n",
       "\" style=\"fill:#ffffff;\"/>\n",
       "   </g>\n",
       "   <g clip-path=\"url(#p984e37f1e4)\">\n",
       "    <image height=\"218\" id=\"imagefa808b51d6\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"20.5625\" xlink:href=\"data:image/png;base64,\n",
       "iVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAADpElEQVR4nO3cv6vOfRzH8fflXMevGOVHEind2ZSSQcoiZVHKRLLJZjRZdHePlnu3nMHgrzEom9Apmxwdv87xV3jK8Xj8A69ruJ7f9/ZZzNl721P5vpFNzY/NbmtmZnur3aus7MmmrvxzONuambl7fV+2tStbgr+Y0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CCwnK0v3dr3z93WTrZYyabOnTiSbV29eCDbmpn5/8WnbMtFg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQILCcrx9/92/YGRbdN+vUkRPZ1sNbu7Ot/9Y2sq2ZmZfv1rMtFw0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CCw/N0/4JcJ38KfmTl26GS29fj2arb19PlmtvXy7ftsa2Zmtr5lUy4aBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGgfZJ8MVKNnXh9PFsa2bmzrW92da/a5+zrVfv3mZbs/2j24q5aBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSWs2s1Gzt/8li2df/GvmxrZubRs81s6/2HN9nWbG91W7VFd2dcNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQJCg4DQICA0CAgNAkKDgNAgIDQICA0CQoOA0CAgNAgIDQLLS2eOZmM3Lh/Itp6sbWRbM57p/iMt92dTLhoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFg+eDm3mzs6fNP2dbr9fVsa2Z27nv4i/BbvNL9F2dmZvVgNuWiQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEBAaBIQGAaFBQGgQEBoEhAYBoUFAaBAQGgSEBgGhQUBoEPgJ7spA+86/fmoAAAAASUVORK5CYII=\" y=\"-6.64\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L 0 3.5 \n",
       "\" id=\"me7bfc50d68\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"34.1525\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(30.97125 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 33.015625 40.375 \n",
       "Q 26.375 40.375 22.484375 35.828125 \n",
       "Q 18.609375 31.296875 18.609375 23.390625 \n",
       "Q 18.609375 15.53125 22.484375 10.953125 \n",
       "Q 26.375 6.390625 33.015625 6.390625 \n",
       "Q 39.65625 6.390625 43.53125 10.953125 \n",
       "Q 47.40625 15.53125 47.40625 23.390625 \n",
       "Q 47.40625 31.296875 43.53125 35.828125 \n",
       "Q 39.65625 40.375 33.015625 40.375 \n",
       "z\n",
       "M 52.59375 71.296875 \n",
       "L 52.59375 62.3125 \n",
       "Q 48.875 64.0625 45.09375 64.984375 \n",
       "Q 41.3125 65.921875 37.59375 65.921875 \n",
       "Q 27.828125 65.921875 22.671875 59.328125 \n",
       "Q 17.53125 52.734375 16.796875 39.40625 \n",
       "Q 19.671875 43.65625 24.015625 45.921875 \n",
       "Q 28.375 48.1875 33.59375 48.1875 \n",
       "Q 44.578125 48.1875 50.953125 41.515625 \n",
       "Q 57.328125 34.859375 57.328125 23.390625 \n",
       "Q 57.328125 12.15625 50.6875 5.359375 \n",
       "Q 44.046875 -1.421875 33.015625 -1.421875 \n",
       "Q 20.359375 -1.421875 13.671875 8.265625 \n",
       "Q 6.984375 17.96875 6.984375 36.375 \n",
       "Q 6.984375 53.65625 15.1875 63.9375 \n",
       "Q 23.390625 74.21875 37.203125 74.21875 \n",
       "Q 40.921875 74.21875 44.703125 73.484375 \n",
       "Q 48.484375 72.75 52.59375 71.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-54\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"61.3325\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(58.15125 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 12.40625 8.296875 \n",
       "L 28.515625 8.296875 \n",
       "L 28.515625 63.921875 \n",
       "L 10.984375 60.40625 \n",
       "L 10.984375 69.390625 \n",
       "L 28.421875 72.90625 \n",
       "L 38.28125 72.90625 \n",
       "L 38.28125 8.296875 \n",
       "L 54.390625 8.296875 \n",
       "L 54.390625 0 \n",
       "L 12.40625 0 \n",
       "z\n",
       "\" id=\"DejaVuSans-49\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"88.5125\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(85.33125 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"115.6925\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(112.51125 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 37.796875 64.3125 \n",
       "L 12.890625 25.390625 \n",
       "L 37.796875 25.390625 \n",
       "z\n",
       "M 35.203125 72.90625 \n",
       "L 47.609375 72.90625 \n",
       "L 47.609375 25.390625 \n",
       "L 58.015625 25.390625 \n",
       "L 58.015625 17.1875 \n",
       "L 47.609375 17.1875 \n",
       "L 47.609375 0 \n",
       "L 37.796875 0 \n",
       "L 37.796875 17.1875 \n",
       "L 4.890625 17.1875 \n",
       "L 4.890625 26.703125 \n",
       "z\n",
       "\" id=\"DejaVuSans-52\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"142.8725\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(139.69125 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"170.0525\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(166.87125 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 19.1875 8.296875 \n",
       "L 53.609375 8.296875 \n",
       "L 53.609375 0 \n",
       "L 7.328125 0 \n",
       "L 7.328125 8.296875 \n",
       "Q 12.9375 14.109375 22.625 23.890625 \n",
       "Q 32.328125 33.6875 34.8125 36.53125 \n",
       "Q 39.546875 41.84375 41.421875 45.53125 \n",
       "Q 43.3125 49.21875 43.3125 52.78125 \n",
       "Q 43.3125 58.59375 39.234375 62.25 \n",
       "Q 35.15625 65.921875 28.609375 65.921875 \n",
       "Q 23.96875 65.921875 18.8125 64.3125 \n",
       "Q 13.671875 62.703125 7.8125 59.421875 \n",
       "L 7.8125 69.390625 \n",
       "Q 13.765625 71.78125 18.9375 73 \n",
       "Q 24.125 74.21875 28.421875 74.21875 \n",
       "Q 39.75 74.21875 46.484375 68.546875 \n",
       "Q 53.21875 62.890625 53.21875 53.421875 \n",
       "Q 53.21875 48.921875 51.53125 44.890625 \n",
       "Q 49.859375 40.875 45.40625 35.40625 \n",
       "Q 44.1875 33.984375 37.640625 27.21875 \n",
       "Q 31.109375 20.453125 19.1875 8.296875 \n",
       "z\n",
       "\" id=\"DejaVuSans-50\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"197.2325\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(194.05125 239.238437)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.4125\" xlink:href=\"#me7bfc50d68\" y=\"224.64\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(221.23125 239.238437)scale(0.1 -0.1)\">\n",
       "       <defs>\n",
       "        <path d=\"M 10.796875 72.90625 \n",
       "L 49.515625 72.90625 \n",
       "L 49.515625 64.59375 \n",
       "L 19.828125 64.59375 \n",
       "L 19.828125 46.734375 \n",
       "Q 21.96875 47.46875 24.109375 47.828125 \n",
       "Q 26.265625 48.1875 28.421875 48.1875 \n",
       "Q 40.625 48.1875 47.75 41.5 \n",
       "Q 54.890625 34.8125 54.890625 23.390625 \n",
       "Q 54.890625 11.625 47.5625 5.09375 \n",
       "Q 40.234375 -1.421875 26.90625 -1.421875 \n",
       "Q 22.3125 -1.421875 17.546875 -0.640625 \n",
       "Q 12.796875 0.140625 7.71875 1.703125 \n",
       "L 7.71875 11.625 \n",
       "Q 12.109375 9.234375 16.796875 8.0625 \n",
       "Q 21.484375 6.890625 26.703125 6.890625 \n",
       "Q 35.15625 6.890625 40.078125 11.328125 \n",
       "Q 45.015625 15.765625 45.015625 23.390625 \n",
       "Q 45.015625 31 40.078125 35.4375 \n",
       "Q 35.15625 39.890625 26.703125 39.890625 \n",
       "Q 22.75 39.890625 18.8125 39.015625 \n",
       "Q 14.890625 38.140625 10.796875 36.28125 \n",
       "z\n",
       "\" id=\"DejaVuSans-53\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <defs>\n",
       "       <path d=\"M 0 0 \n",
       "L -3.5 0 \n",
       "\" id=\"m24bea38cee\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n",
       "      </defs>\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"211.05\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 6 -->\n",
       "      <g transform=\"translate(7.2 214.849219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-54\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"183.87\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(7.2 187.669219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"156.69\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(7.2 160.489219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"129.51\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 4 -->\n",
       "      <g transform=\"translate(7.2 133.309219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-52\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"102.33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(7.2 106.129219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"75.15\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 2 -->\n",
       "      <g transform=\"translate(7.2 78.949219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-50\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"47.97\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 1 -->\n",
       "      <g transform=\"translate(7.2 51.769219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-49\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <g>\n",
       "       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"20.5625\" xlink:href=\"#m24bea38cee\" y=\"20.79\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 5 -->\n",
       "      <g transform=\"translate(7.2 24.589219)scale(0.1 -0.1)\">\n",
       "       <use xlink:href=\"#DejaVuSans-53\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 20.5625 224.64 \n",
       "L 20.5625 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 238.0025 224.64 \n",
       "L 238.0025 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 20.5625 224.64 \n",
       "L 238.0025 224.64 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 20.5625 7.2 \n",
       "L 238.0025 7.2 \n",
       "\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p984e37f1e4\">\n",
       "   <rect height=\"217.44\" width=\"217.44\" x=\"20.5625\" y=\"7.2\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_attention_maps(data_input, attention_maps, idx=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 1, 1, 4, 1, 2, 1, 5])\n",
      "tensor([[[4.7970e-02, 2.6815e-02, 4.4109e-03, 1.4220e-03, 1.7083e-03,\n",
      "          1.8437e-02, 2.4641e-01, 6.5283e-01],\n",
      "         [3.1395e-02, 3.0637e-03, 4.6369e-04, 8.0842e-04, 8.5168e-03,\n",
      "          1.8777e-01, 5.5494e-01, 2.1304e-01],\n",
      "         [2.8400e-03, 3.8710e-04, 4.2181e-04, 5.5100e-03, 1.4229e-01,\n",
      "          6.5739e-01, 1.7384e-01, 1.7325e-02],\n",
      "         [5.7960e-04, 7.2042e-04, 7.4494e-03, 1.2699e-01, 6.5162e-01,\n",
      "          1.9578e-01, 1.4233e-02, 2.6273e-03],\n",
      "         [1.0191e-03, 1.0865e-02, 2.0937e-01, 6.0494e-01, 1.6160e-01,\n",
      "          8.6435e-03, 1.3779e-03, 2.1953e-03],\n",
      "         [1.3675e-02, 1.9795e-01, 6.4836e-01, 1.2724e-01, 4.4468e-03,\n",
      "          4.2269e-04, 6.7687e-04, 7.2339e-03],\n",
      "         [2.3015e-01, 5.7746e-01, 1.5313e-01, 7.5713e-03, 4.0953e-04,\n",
      "          3.4819e-04, 2.5340e-03, 2.8401e-02],\n",
      "         [6.7629e-01, 2.1667e-01, 1.8641e-02, 2.2116e-03, 1.0875e-03,\n",
      "          4.9765e-03, 2.5343e-02, 5.4779e-02]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(data_input[2])\n",
    "print(attention_maps[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
