{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 5.1: Inception, ResNet and DenseNet\n",
    "\n",
    "In this tutorial, we will implement and discuss variants of modern CNN architectures.\n",
    "\n",
    "We use PyTorch Lightning for the first time here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_NOTEBOOK = False\n",
    "TEST_NOTEBOOK = False\n",
    "TRAIN_GOOGLENET = True\n",
    "TRAIN_RESNET = True\n",
    "TRAIN_DENSENET = True\n",
    "\n",
    "## Standard libraries\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import numpy as np \n",
    "import scipy.linalg\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "if USE_NOTEBOOK:\n",
    "    %matplotlib inline \n",
    "    from IPython.display import set_matplotlib_formats\n",
    "    set_matplotlib_formats('svg', 'pdf') # For export\n",
    "    from matplotlib.colors import to_rgb\n",
    "    import matplotlib\n",
    "    matplotlib.rcParams['lines.linewidth'] = 2.0\n",
    "import seaborn as sns\n",
    "sns.reset_orig()\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "## PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "# Torchvision\n",
    "import torchvision\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision import transforms\n",
    "# PyTorch Lightning\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "\n",
    "if USE_NOTEBOOK:\n",
    "    # Tensorboard extension (for looking at tensorboard inside jupyter notebook)\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    %load_ext tensorboard\n",
    "\n",
    "# Path to the folder where the datasets are/should be downloaded (e.g. CIFAR10)\n",
    "DATASET_PATH = \"../data\"\n",
    "# Path to the folder where the pretrained models are saved\n",
    "CHECKPOINT_PATH = \"../saved_models/tutorial5\"\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout this tutorial, we use the CIFAR dataset. (We can change the dataset if necessary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transformations applied on each image => make them a tensor and normalize\n",
    "test_transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "                                     ])\n",
    "# For training, we add some augmentation. Networks are too powerful and would overfit.\n",
    "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.RandomResizedCrop((32,32),scale=(0.8,1.0),ratio=(0.9,1.1)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
    "                                     ])\n",
    "# Loading the training dataset. We need to split it into a training and validation part\n",
    "# We need to do a little trick because the validation set should not use the augmentation.\n",
    "train_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=train_transform, download=True)\n",
    "val_dataset = CIFAR10(root=DATASET_PATH, train=True, transform=test_transform, download=True)\n",
    "pl.seed_everything(42)\n",
    "train_set, _ = torch.utils.data.random_split(train_dataset, [45000, 5000])\n",
    "pl.seed_everything(42)\n",
    "_, val_set = torch.utils.data.random_split(val_dataset, [45000, 5000])\n",
    "\n",
    "# Loading the test set\n",
    "test_set = CIFAR10(root=DATASET_PATH, train=False, transform=test_transform, download=True)\n",
    "\n",
    "# We define a set of data loaders that we can use for various purposes later.\n",
    "# Note that for actually training a model, we will use different data loaders\n",
    "# with a lower batch size.\n",
    "train_loader = data.DataLoader(train_set, batch_size=128, shuffle=True, drop_last=True, pin_memory=True, num_workers=4)\n",
    "val_loader = data.DataLoader(val_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)\n",
    "test_loader = data.DataLoader(test_set, batch_size=64, shuffle=False, drop_last=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean [0.49139968 0.48215841 0.44653091]\n",
      "Std [0.24703223 0.24348513 0.26158784]\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean\", (train_dataset.data / 255.0).mean(axis=(0,1,2)))\n",
    "print(\"Std\", (train_dataset.data / 255.0).std(axis=(0,1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean tensor([-0.0143, -0.0206, -0.0016])\n",
      "Std tensor([0.9773, 0.9649, 0.9808])\n"
     ]
    }
   ],
   "source": [
    "imgs, _ = next(iter(train_loader))\n",
    "print(\"Mean\", imgs.mean(dim=[0,2,3]))\n",
    "print(\"Std\", imgs.std(dim=[0,2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_NOTEBOOK:\n",
    "    NUM_IMAGES = 4\n",
    "    images = [train_dataset[idx][0] for idx in range(NUM_IMAGES)]\n",
    "    orig_images = [Image.fromarray(train_dataset.data[idx]) for idx in range(NUM_IMAGES)]\n",
    "    orig_images = [test_transform(img) for img in orig_images]\n",
    "\n",
    "    img_grid = torchvision.utils.make_grid(torch.stack(images + orig_images, dim=0), nrow=4, normalize=True, pad_value=0.5)\n",
    "    img_grid = img_grid.permute(1, 2, 0)\n",
    "\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.title(\"Augmentation examples on CIFAR10\")\n",
    "    plt.imshow(img_grid)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_fn_by_name = {\n",
    "    \"tanh\": nn.Tanh,\n",
    "    \"relu\": nn.ReLU,\n",
    "    \"leakyrelu\": nn.LeakyReLU,\n",
    "    \"gelu\": nn.GELU\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = {}\n",
    "\n",
    "def create_model(model_name, model_hparams):\n",
    "    if model_name in model_dict:\n",
    "        return model_dict[model_name](**model_hparams)\n",
    "    else:\n",
    "        assert False, \"Unknown model name \\\"%s\\\". Available models are: %s\" % (model_name, str(model_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CIFARTrainer(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self, model_name, model_hparams, optimizer_name, optimizer_hparams):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Create model\n",
    "        self.model = create_model(model_name, model_hparams)\n",
    "        # Create loss module\n",
    "        self.loss_module = nn.CrossEntropyLoss()\n",
    "        # Example input for visualizing the graph\n",
    "        self.example_input_array = torch.zeros((1, 3, 32, 32), dtype=torch.float32)\n",
    "    \n",
    "    \n",
    "    def forward(self, imgs):\n",
    "        return self.model(imgs)\n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        if self.hparams.optimizer_name == \"Adam\":\n",
    "            optimizer = optim.AdamW(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        elif self.hparams.optimizer_name == \"SGD\":\n",
    "            optimizer = optim.SGD(self.parameters(), **self.hparams.optimizer_hparams)\n",
    "        else:\n",
    "            assert False, \"Unknown optimizer: \\\"%s\\\"\" % self.hparams.optimizer_name\n",
    "        scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,150], gamma=0.1)\n",
    "        return [optimizer], [scheduler]\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs)\n",
    "        loss = self.loss_module(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "        \n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True)\n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "        self.log('val_acc', acc)\n",
    "        \n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        imgs, labels = batch\n",
    "        preds = self.model(imgs).argmax(dim=-1)\n",
    "        acc = (labels == preds).float().mean()\n",
    "        self.log('test_acc', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model_name, save_name=None, **kwargs):\n",
    "    if save_name is None:\n",
    "        save_name = model_name\n",
    "    # Create a PyTorch Lightning trainer with the generation callback\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, save_name),\n",
    "                         checkpoint_callback=ModelCheckpoint(save_weights_only=True, mode=\"max\", monitor=\"val_acc\"),\n",
    "                         gpus=1,\n",
    "                         max_epochs=180 if not TEST_NOTEBOOK else 1,\n",
    "                         callbacks=[LearningRateMonitor(\"epoch\")],\n",
    "                         progress_bar_refresh_rate=0 if not USE_NOTEBOOK else 1)\n",
    "    trainer.logger._log_graph = True\n",
    "    trainer.logger._default_hp_metric = None\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, save_name + \".ckpt\")\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(\"Found pretrained model, loading...\")\n",
    "        model = CIFARTrainer.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = CIFARTrainer(model_name=model_name, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "    # Test best model on validation and test set\n",
    "    val_result = trainer.test(model, test_dataloaders=val_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_dataloaders=test_loader, verbose=False)\n",
    "    result = {\"test\": test_result[0][\"test_acc\"], \"val\": val_result[0][\"test_acc\"]}\n",
    "    return model, result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GoogleNet](https://arxiv.org/abs/1409.4842)\n",
    "\n",
    "<img src=\"inception_block.svg\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"40%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InceptionBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_red : dict, c_out : dict, act_fn):\n",
    "        super().__init__()\n",
    "        self.conv_1x1 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out[\"1x1\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_out[\"1x1\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "        self.conv_3x3 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"3x3\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"3x3\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"3x3\"], c_out[\"3x3\"], kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(c_out[\"3x3\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "        self.conv_5x5 = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_red[\"5x5\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_red[\"5x5\"]),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_red[\"5x5\"], c_out[\"5x5\"], kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(c_out[\"5x5\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "        self.max_pool = nn.Sequential(\n",
    "            nn.MaxPool2d(kernel_size=3, padding=1, stride=1),\n",
    "            nn.Conv2d(c_in, c_out[\"max\"], kernel_size=1),\n",
    "            nn.BatchNorm2d(c_out[\"max\"]),\n",
    "            act_fn()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x_1x1 = self.conv_1x1(x)\n",
    "        x_3x3 = self.conv_3x3(x)\n",
    "        x_5x5 = self.conv_5x5(x)\n",
    "        x_max = self.max_pool(x)\n",
    "        x_out = torch.cat([x_1x1, x_3x3, x_5x5, x_max], dim=1)\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10, act_fn_name=\"relu\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.hparams = {\"num_classes\": num_classes, \n",
    "                        \"act_fn_name\": act_fn_name, \n",
    "                        \"act_fn\": act_fn_by_name[act_fn_name]}\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "    \n",
    "    \n",
    "    def _create_network(self):\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            self.hparams[\"act_fn\"]()\n",
    "        )\n",
    "        self.inception_blocks = nn.Sequential(\n",
    "            InceptionBlock(64, c_red={\"3x3\":32,\"5x5\":16}, c_out={\"1x1\":16,\"3x3\":32,\"5x5\":8,\"max\":8}, act_fn=self.hparams[\"act_fn\"]),\n",
    "            InceptionBlock(64, c_red={\"3x3\":32,\"5x5\":16}, c_out={\"1x1\":24,\"3x3\":48,\"5x5\":12,\"max\":12}, act_fn=self.hparams[\"act_fn\"]),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            InceptionBlock(96, c_red={\"3x3\":32,\"5x5\":16}, c_out={\"1x1\":24,\"3x3\":48,\"5x5\":12,\"max\":12}, act_fn=self.hparams[\"act_fn\"]),\n",
    "            InceptionBlock(96, c_red={\"3x3\":32,\"5x5\":16}, c_out={\"1x1\":16,\"3x3\":48,\"5x5\":16,\"max\":16}, act_fn=self.hparams[\"act_fn\"]),\n",
    "            InceptionBlock(96, c_red={\"3x3\":32,\"5x5\":16}, c_out={\"1x1\":16,\"3x3\":48,\"5x5\":16,\"max\":16}, act_fn=self.hparams[\"act_fn\"]),\n",
    "            InceptionBlock(96, c_red={\"3x3\":32,\"5x5\":16}, c_out={\"1x1\":32,\"3x3\":48,\"5x5\":24,\"max\":24}, act_fn=self.hparams[\"act_fn\"]),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1),\n",
    "            InceptionBlock(128, c_red={\"3x3\":48,\"5x5\":16}, c_out={\"1x1\":32,\"3x3\":64,\"5x5\":16,\"max\":16}, act_fn=self.hparams[\"act_fn\"]),\n",
    "            InceptionBlock(128, c_red={\"3x3\":48,\"5x5\":16}, c_out={\"1x1\":32,\"3x3\":64,\"5x5\":16,\"max\":16}, act_fn=self.hparams[\"act_fn\"])\n",
    "        )\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128, self.hparams[\"num_classes\"])\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def _init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=self.hparams[\"act_fn_name\"])\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "                \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.inception_blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"GoogleNet\"] = GoogleNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | GoogleNet        | 260 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I1014 10:17:30.491847 139989529995072 lightning.py:1288] \n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | GoogleNet        | 260 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n"
     ]
    }
   ],
   "source": [
    "if TRAIN_GOOGLENET:\n",
    "    googlenet_model, googlenet_results = train_model(model_name=\"GoogleNet\", \n",
    "                                                     model_hparams={\"num_classes\": 10, \n",
    "                                                                    \"act_fn_name\": \"relu\"}, \n",
    "                                                     # optimizer_name=\"Adam\",\n",
    "                                                     # optimizer_hparams={\"lr\": 1e-3,\n",
    "                                                     #                    \"weight_decay\": 1e-4}\n",
    "                                                     optimizer_name=\"SGD\",\n",
    "                                                     optimizer_hparams={\"lr\": 0.1,\n",
    "                                                                        \"weight_decay\": 1e-4})\n",
    "else:\n",
    "    googlenet_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GoogleNet Results {'test': 0.48510000109672546, 'val': 0.4936000108718872}\n"
     ]
    }
   ],
   "source": [
    "print(\"GoogleNet Results\", googlenet_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    "[ResNet](https://arxiv.org/abs/1512.03385), [Pre-Activation ResNet](https://arxiv.org/abs/1603.05027)\n",
    "\n",
    "<img src=\"resnet_block.svg\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"25%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
    "        super().__init__()\n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(c_out)\n",
    "        )\n",
    "        # 1x1 convolution with stride 2 means we take the upper left value, and transform it to new output size\n",
    "        self.downsample = nn.Conv2d(c_in, c_out, kernel_size=1, stride=2) if subsample else None\n",
    "        self.act_fn = act_fn()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        z = z + x\n",
    "        out = self.act_fn(z)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreActResNetBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, c_in, act_fn, subsample=False, c_out=-1):\n",
    "        super().__init__()\n",
    "        if not subsample:\n",
    "            c_out = c_in\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=3, padding=1, stride=1 if not subsample else 2, bias=False),\n",
    "            nn.BatchNorm2d(c_out),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_out, c_out, kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "        # 1x1 convolution with stride 2 means we take the upper left value, and transform it to new output size\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=1, stride=2, bias=False)\n",
    "        ) if subsample else None\n",
    "        self.act_fn = act_fn()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        z = self.net(x)\n",
    "        if self.downsample is not None:\n",
    "            x = self.downsample(x)\n",
    "        out = z + x\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_blocks_by_name = {\n",
    "    \"ResNetBlock\": ResNetBlock,\n",
    "    \"PreActResNetBlock\": PreActResNetBlock\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=10, c_hidden=[16,32,64], num_blocks=[3,3,3], act_fn_name=\"relu\", block_name=\"ResNetBlock\", **kwargs):\n",
    "        super().__init__()\n",
    "        assert block_name in resnet_blocks_by_name\n",
    "        self.hparams = {\"num_classes\": num_classes, \n",
    "                        \"c_hidden\": c_hidden, \n",
    "                        \"num_blocks\": num_blocks, \n",
    "                        \"act_fn_name\": act_fn_name,\n",
    "                        \"act_fn\": act_fn_by_name[act_fn_name],\n",
    "                        \"block_class\": resnet_blocks_by_name[block_name]}\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "\n",
    "        \n",
    "    def _create_network(self):\n",
    "        c_hidden = self.hparams[\"c_hidden\"]\n",
    "        if self.hparams[\"block_class\"] == PreActResNetBlock:\n",
    "            self.input_net = nn.Sequential(\n",
    "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1)\n",
    "            )\n",
    "        else:\n",
    "            self.input_net = nn.Sequential(\n",
    "                nn.Conv2d(3, c_hidden[0], kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(c_hidden[0]),\n",
    "                self.hparams[\"act_fn\"]()\n",
    "            )\n",
    "        blocks = []\n",
    "        for block_idx, block_count in enumerate(self.hparams[\"num_blocks\"]):\n",
    "            for bc in range(block_count):\n",
    "                subsample = (bc == 0 and block_idx > 0)\n",
    "                blocks.append(\n",
    "                    self.hparams[\"block_class\"](c_in=c_hidden[block_idx if not subsample else (block_idx-1)],\n",
    "                                                act_fn=self.hparams[\"act_fn\"],\n",
    "                                                subsample=subsample,\n",
    "                                                c_out=c_hidden[block_idx])\n",
    "                )\n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(c_hidden[-1], self.hparams[\"num_classes\"])\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def _init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity=self.hparams[\"act_fn_name\"])\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"ResNet\"] = ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "I1014 10:18:00.885122 139989529995072 distributed.py:49] GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "I1014 10:18:00.887254 139989529995072 distributed.py:49] TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I1014 10:18:00.888556 139989529995072 accelerator_connector.py:385] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | ResNet           | 273 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n",
      "I1014 10:18:02.715720 139989529995072 lightning.py:1288] \n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | ResNet           | 273 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n"
     ]
    }
   ],
   "source": [
    "if TRAIN_RESNET:\n",
    "    resnet_model, resnet_results = train_model(model_name=\"ResNet\", \n",
    "                                               model_hparams={\"num_classes\": 10,\n",
    "                                                              \"c_hidden\": [16,32,64],\n",
    "                                                              \"num_blocks\": [3,3,3],\n",
    "                                                              \"act_fn_name\": \"relu\"}, \n",
    "                                               optimizer_name=\"SGD\",\n",
    "                                               optimizer_hparams={\"lr\": 0.1,\n",
    "                                                                  \"momentum\": 0.9,\n",
    "                                                                  \"weight_decay\": 1e-4})\n",
    "else:\n",
    "    resnet_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet results {'test': 0.49639999866485596, 'val': 0.4830000102519989}\n"
     ]
    }
   ],
   "source": [
    "print(\"ResNet results\", resnet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "I1014 10:18:14.181275 139989529995072 distributed.py:49] GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "I1014 10:18:14.183471 139989529995072 distributed.py:49] TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I1014 10:18:14.184689 139989529995072 accelerator_connector.py:385] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | ResNet           | 272 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n",
      "I1014 10:18:16.207663 139989529995072 lightning.py:1288] \n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | ResNet           | 272 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n"
     ]
    }
   ],
   "source": [
    "if TRAIN_RESNET:\n",
    "    resnet_model, resnet_results = train_model(model_name=\"ResNet\", \n",
    "                                               model_hparams={\"num_classes\": 10,\n",
    "                                                              \"c_hidden\": [16,32,64],\n",
    "                                                              \"num_blocks\": [3,3,3],\n",
    "                                                              \"act_fn_name\": \"relu\",\n",
    "                                                              \"block_name\": \"PreActResNetBlock\"}, \n",
    "                                               optimizer_name=\"SGD\",\n",
    "                                               optimizer_hparams={\"lr\": 0.1,\n",
    "                                                                  \"momentum\": 0.9,\n",
    "                                                                  \"weight_decay\": 1e-4},\n",
    "                                               save_name=\"ResNetPreAct\")\n",
    "else:\n",
    "    resnet_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PreActResnet results {'test': 0.48510000109672546, 'val': 0.4896000027656555}\n"
     ]
    }
   ],
   "source": [
    "print(\"PreActResnet results\", resnet_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DenseNet\n",
    "\n",
    "[DenseNet](https://arxiv.org/abs/1608.06993)\n",
    "\n",
    "<img src=\"densenet_block.svg\" style=\"display: block; margin-left: auto; margin-right: auto;\" width=\"40%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, bn_size, growth_rate, act_fn):\n",
    "        \"\"\"\n",
    "            bn_size - Bottleneck size (factor of growth rate)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, bn_size * growth_rate, kernel_size=1, bias=False),\n",
    "            nn.BatchNorm2d(bn_size * growth_rate),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(bn_size * growth_rate, growth_rate, kernel_size=3, padding=1, bias=False)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        out = torch.cat([out, x], dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, num_layers, bn_size, growth_rate, act_fn):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        for layer_idx in range(num_layers):\n",
    "            layers.append(\n",
    "                DenseLayer(c_in=c_in + layer_idx * growth_rate,\n",
    "                           bn_size=bn_size,\n",
    "                           growth_rate=growth_rate,\n",
    "                           act_fn=act_fn)\n",
    "            )\n",
    "        self.block = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReductionLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, c_in, c_out, act_fn):\n",
    "        super().__init__()\n",
    "        self.reduction = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_in),\n",
    "            act_fn(),\n",
    "            nn.Conv2d(c_in, c_out, kernel_size=1, bias=False),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.reduction(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=10, num_layers=[6,6,6,6], bn_size=2, growth_rate=16, act_fn_name=\"relu\", **kwargs):\n",
    "        super().__init__()\n",
    "        self.hparams = {\"num_classes\": num_classes,\n",
    "                        \"num_layers\": num_layers,\n",
    "                        \"bn_size\": bn_size,\n",
    "                        \"growth_rate\": growth_rate,\n",
    "                        \"act_fn_name\": act_fn_name,\n",
    "                        \"act_fn\": act_fn_by_name[act_fn_name]}\n",
    "        self._create_network()\n",
    "        self._init_params()\n",
    "        \n",
    "    def _create_network(self):\n",
    "        c_hidden = self.hparams[\"growth_rate\"] * self.hparams[\"bn_size\"]\n",
    "        self.input_net = nn.Sequential(\n",
    "            nn.Conv2d(3, c_hidden, kernel_size=3, padding=1) # No batch norm or activation function as done inside the Dense layers\n",
    "        )\n",
    "        blocks = []\n",
    "        for block_idx, num_layers in enumerate(self.hparams[\"num_layers\"]):\n",
    "            blocks.append( \n",
    "                DenseBlock(c_in=c_hidden, \n",
    "                           num_layers=num_layers, \n",
    "                           bn_size=self.hparams[\"bn_size\"],\n",
    "                           growth_rate=self.hparams[\"growth_rate\"],\n",
    "                           act_fn=self.hparams[\"act_fn\"])\n",
    "            )\n",
    "            c_hidden = c_hidden + num_layers * self.hparams[\"growth_rate\"]\n",
    "            if block_idx < len(self.hparams[\"num_layers\"])-1:\n",
    "                blocks.append(\n",
    "                    ReductionLayer(c_in=c_hidden,\n",
    "                                   c_out=c_hidden // 2,\n",
    "                                   act_fn=self.hparams[\"act_fn\"]))\n",
    "                c_hidden = c_hidden // 2\n",
    "                \n",
    "        self.blocks = nn.Sequential(*blocks)\n",
    "        self.output_net = nn.Sequential(\n",
    "            nn.BatchNorm2d(c_hidden),\n",
    "            self.hparams[\"act_fn\"](),\n",
    "            nn.AdaptiveAvgPool2d((1,1)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(c_hidden, self.hparams[\"num_classes\"])\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def _init_params(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity=self.hparams[\"act_fn_name\"])\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.input_net(x)\n",
    "        x = self.blocks(x)\n",
    "        x = self.output_net(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict[\"DenseNet\"] = DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "I1014 10:19:23.085230 139989529995072 distributed.py:49] GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "I1014 10:19:23.087361 139989529995072 distributed.py:49] TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "I1014 10:19:23.088768 139989529995072 accelerator_connector.py:385] LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | DenseNet         | 239 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n",
      "I1014 10:19:24.445253 139989529995072 lightning.py:1288] \n",
      "  | Name        | Type             | Params | In sizes       | Out sizes\n",
      "------------------------------------------------------------------------------\n",
      "0 | model       | DenseNet         | 239 K  | [1, 3, 32, 32] | [1, 10]  \n",
      "1 | loss_module | CrossEntropyLoss | 0      | ?              | ?        \n"
     ]
    }
   ],
   "source": [
    "if TRAIN_DENSENET:\n",
    "    densenet_model, densenet_results = train_model(model_name=\"DenseNet\", \n",
    "                                                   model_hparams={\"num_classes\": 10,\n",
    "                                                                  \"num_layers\": [6,6,6,6],\n",
    "                                                                  \"bn_size\": 2,\n",
    "                                                                  \"growth_rate\": 16,\n",
    "                                                                  \"act_fn_name\": \"relu\"}, \n",
    "                                                   # optimizer_name=\"Adam\",\n",
    "                                                   # optimizer_hparams={\"lr\": 1e-3,\n",
    "                                                   #                    \"weight_decay\": 1e-4}\n",
    "                                                   optimizer_name=\"SGD\",\n",
    "                                                   optimizer_hparams={\"lr\": 0.1,\n",
    "                                                                      \"weight_decay\": 1e-4})\n",
    "else:\n",
    "    densenet_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': 0.46380001306533813, 'val': 0.47620001435279846}\n"
     ]
    }
   ],
   "source": [
    "print(densenet_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = model_dict[\"ResNet\"](efficient_blocks=True)\n",
    "# print(\"Number of parameters\", sum([np.prod(p.shape) for p in model.parameters()]))\n",
    "# print(\"Parameter count per weights\", \"\\n\".join([\"%s: %i (%s)\" % (n, np.prod(p.shape), str([e for e in p.shape])) for n, p in model.named_parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
